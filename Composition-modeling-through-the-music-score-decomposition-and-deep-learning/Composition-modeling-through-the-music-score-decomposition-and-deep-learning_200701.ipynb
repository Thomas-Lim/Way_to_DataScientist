{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "악보분해와 딥러닝을 통한 작곡 모델링_200701.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "moW8AjpQ11UN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "847b6554-e017-4c56-ba60-0596f0bbfbcf"
      },
      "source": [
        "# 목표 : 첫 4개 음표를 입력하면 나머지를 연주할 수 있는 모델을 만드는 것이 목표\n",
        "\n",
        "\n",
        "# 0. 사용할 패키지 불러오기\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "# 랜덤시드 고정시키기\n",
        "np.random.seed(5)\n",
        "\n",
        "# 데이터셋 생성 함수        \n",
        "def seq2dataset(seq, window_size):    # 아래에서 지정할 윈도우 크기만큼 자르는 함수\n",
        "    dataset = []\n",
        "    for i in range(len(seq)-window_size):    # 만약 seq 30 - 4 : 26 범위이면, 0~25\n",
        "        subset = seq[i:(i+window_size+1)]    # seq i:~ i+window_size+1 만큼 해서 dataset에 넣어준다.\n",
        "        dataset.append([code2idx[item] for item in subset])\n",
        "    return np.array(dataset)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wcq_l-kkfCcZ",
        "colab_type": "text"
      },
      "source": [
        "#g4\te8f8 g4\te8f8 g8b8a8b8 c8e8e8f8 e4 c8e8 e4     e8f8 g8a8g8f8  g8c8b8c8  \n",
        "\t\t\t\n",
        "\t\t\t\n",
        "#a4\tc8b8 a4\tg8f8 g8f8e8f8g8a8b8c8a8\tc4b8c8    b8c8\tb8a8b8c8e8e8f8g8  \n",
        "\n",
        "\n",
        "#g4e8f8g4 \te8f8g8b8 a8b8c8e8 e4 f8e8\t  c4 e8e8   e8f8 g8a8g8f8g8c8b8c8\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "#a4\tc8b8a4\tg8f8g8f8 e8f8g8a8 b4 c8a8 c4 a8c8\tb8c8e8c8b8c8a8b8\n",
        "\n",
        "\n",
        "# https://m.blog.naver.com/PostView.nhn?blogId=ahyoon08&logNo=221008211738&proxyReferer=https:%2F%2Fwww.google.com%2F&view=img_10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmwnghgRrWUr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "음계가 문장보다 더 코드화 하기 쉬움.\n",
        "시계열 자료임.\n",
        "\n",
        "c(도), d(레), e(미), f(파), g(솔), a(라), b(시)\n",
        "4(4분음표), 8(8분음표)\n",
        "\n",
        "6개의 음표로는 위와 같이 2개의 샘플이 나옴. \n",
        "각 샘플은 4개의 입력 데이터와 1개의 라벨값으로 구성되어 있음. \n",
        "즉 1~4번째 열은 속성(feature)이고, 5번째 열은 y임.\n",
        "이렇게 4개씩 구간을 보는 것을 '윈도우 크기 4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvEIamd2rWnI",
        "colab_type": "text"
      },
      "source": [
        "문자와 숫자로 된 음표(코드)로는 모델 입출력으로 사용할 수 없다.\n",
        "아래 사전에서,\n",
        "-> 첫번째 사전 : 숫자\n",
        "-> 두번째 사전 : 코드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VddDA1zjrU-I",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u1qfx9x12lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. 데이터 준비하기. 나온 것들 하나씩 Unique 하게 나열.\n",
        "# 코드 사전 정의\n",
        "# 코드를 숫자로\n",
        "code2idx = {'a4':0, 'a8':1, 'b4':2, 'b8':3, 'c4':4, 'c8':5, \n",
        "            'e4':6, 'e8':7, 'f8':8, 'g4':9, 'g8':10}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 숫자를 코드로\n",
        "idx2code = {0:'a4', 1:'a8', 2:'b4', 3:'b8', 4:'c4', 5:'c8', \n",
        "            6:'e4', 7:'e8', 8:'f8', 9:'g4', 10:'g8'}\n",
        "\n",
        "# 시퀀스 데이터 정의\n",
        "\n",
        "seq = ['g4','e8','f8','g4','e8','f8','g8','b8','a8','b8','c8','e8','e8','f8','e4','c8','e8','e4','e8','f8','g8','a8','g8','f8','g8','c8','b8','c8',\n",
        "'a4','c8','b8','a4','g8','f8','g8','f8','e8','f8','g8','a8','b8','c8','a8','c4','b8','c8','b8','c8','b8','a8','b8','c8','e8','e8','f8','g8',\n",
        "'g4','e8','f8','g4','e8','f8','g8','b8','a8','b8','c8','e8','e4','f8','e8','c4','e8','e8','e8','f8','g8','a8','g8','f8','g8','c8','b8','c8',\n",
        "'a4','c8','b8','a4','g8','f8','g8','f8','e8','f8','g8','a8','b4','c8','a8','c4','a8','c8','b8','c8','e8','c8','b8','c8','a8','b8']    # 악보 전체 입력."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx5EsPdG15JQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5651f59e-5ab7-4716-e079-b807376db9ca"
      },
      "source": [
        "# 2. 데이터셋 생성하기     seq2dataset() 함수를 하여 dataset를 생성. 데이터셋은 앞서 정의한 사전에 따라 숫자로 변환되어 생성.\n",
        "dataset = seq2dataset(seq, window_size = 4) # 윈도우 사이즈 4 + 타겟 1 이므로 5임.\n",
        "\n",
        "print(dataset.shape)\n",
        "print(dataset)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(106, 5)\n",
            "[[ 9  7  8  9  7]\n",
            " [ 7  8  9  7  8]\n",
            " [ 8  9  7  8 10]\n",
            " [ 9  7  8 10  3]\n",
            " [ 7  8 10  3  1]\n",
            " [ 8 10  3  1  3]\n",
            " [10  3  1  3  5]\n",
            " [ 3  1  3  5  7]\n",
            " [ 1  3  5  7  7]\n",
            " [ 3  5  7  7  8]\n",
            " [ 5  7  7  8  6]\n",
            " [ 7  7  8  6  5]\n",
            " [ 7  8  6  5  7]\n",
            " [ 8  6  5  7  6]\n",
            " [ 6  5  7  6  7]\n",
            " [ 5  7  6  7  8]\n",
            " [ 7  6  7  8 10]\n",
            " [ 6  7  8 10  1]\n",
            " [ 7  8 10  1 10]\n",
            " [ 8 10  1 10  8]\n",
            " [10  1 10  8 10]\n",
            " [ 1 10  8 10  5]\n",
            " [10  8 10  5  3]\n",
            " [ 8 10  5  3  5]\n",
            " [10  5  3  5  0]\n",
            " [ 5  3  5  0  5]\n",
            " [ 3  5  0  5  3]\n",
            " [ 5  0  5  3  0]\n",
            " [ 0  5  3  0 10]\n",
            " [ 5  3  0 10  8]\n",
            " [ 3  0 10  8 10]\n",
            " [ 0 10  8 10  8]\n",
            " [10  8 10  8  7]\n",
            " [ 8 10  8  7  8]\n",
            " [10  8  7  8 10]\n",
            " [ 8  7  8 10  1]\n",
            " [ 7  8 10  1  3]\n",
            " [ 8 10  1  3  5]\n",
            " [10  1  3  5  1]\n",
            " [ 1  3  5  1  4]\n",
            " [ 3  5  1  4  3]\n",
            " [ 5  1  4  3  5]\n",
            " [ 1  4  3  5  3]\n",
            " [ 4  3  5  3  5]\n",
            " [ 3  5  3  5  3]\n",
            " [ 5  3  5  3  1]\n",
            " [ 3  5  3  1  3]\n",
            " [ 5  3  1  3  5]\n",
            " [ 3  1  3  5  7]\n",
            " [ 1  3  5  7  7]\n",
            " [ 3  5  7  7  8]\n",
            " [ 5  7  7  8 10]\n",
            " [ 7  7  8 10  9]\n",
            " [ 7  8 10  9  7]\n",
            " [ 8 10  9  7  8]\n",
            " [10  9  7  8  9]\n",
            " [ 9  7  8  9  7]\n",
            " [ 7  8  9  7  8]\n",
            " [ 8  9  7  8 10]\n",
            " [ 9  7  8 10  3]\n",
            " [ 7  8 10  3  1]\n",
            " [ 8 10  3  1  3]\n",
            " [10  3  1  3  5]\n",
            " [ 3  1  3  5  7]\n",
            " [ 1  3  5  7  6]\n",
            " [ 3  5  7  6  8]\n",
            " [ 5  7  6  8  7]\n",
            " [ 7  6  8  7  4]\n",
            " [ 6  8  7  4  7]\n",
            " [ 8  7  4  7  7]\n",
            " [ 7  4  7  7  7]\n",
            " [ 4  7  7  7  8]\n",
            " [ 7  7  7  8 10]\n",
            " [ 7  7  8 10  1]\n",
            " [ 7  8 10  1 10]\n",
            " [ 8 10  1 10  8]\n",
            " [10  1 10  8 10]\n",
            " [ 1 10  8 10  5]\n",
            " [10  8 10  5  3]\n",
            " [ 8 10  5  3  5]\n",
            " [10  5  3  5  0]\n",
            " [ 5  3  5  0  5]\n",
            " [ 3  5  0  5  3]\n",
            " [ 5  0  5  3  0]\n",
            " [ 0  5  3  0 10]\n",
            " [ 5  3  0 10  8]\n",
            " [ 3  0 10  8 10]\n",
            " [ 0 10  8 10  8]\n",
            " [10  8 10  8  7]\n",
            " [ 8 10  8  7  8]\n",
            " [10  8  7  8 10]\n",
            " [ 8  7  8 10  1]\n",
            " [ 7  8 10  1  2]\n",
            " [ 8 10  1  2  5]\n",
            " [10  1  2  5  1]\n",
            " [ 1  2  5  1  4]\n",
            " [ 2  5  1  4  1]\n",
            " [ 5  1  4  1  5]\n",
            " [ 1  4  1  5  3]\n",
            " [ 4  1  5  3  5]\n",
            " [ 1  5  3  5  7]\n",
            " [ 5  3  5  7  5]\n",
            " [ 3  5  7  5  3]\n",
            " [ 5  7  5  3  5]\n",
            " [ 7  5  3  5  1]\n",
            " [ 5  3  5  1  3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgz6PirD32ew",
        "colab_type": "text"
      },
      "source": [
        "예측 과정\n",
        "1) 한 스텝 단위 예측 \n",
        "2) 곡 전체 예측입니다.\n",
        "\n",
        "1) 한 스텝 예측\n",
        "한 스텝 예측이란 실제 음표 4개를 입력하여 다음 음표 1개를 예측하는 것을 반복하는 것. \n",
        "\n",
        "2) 곡 전체 예측\n",
        "입력된 초기 4개 음표만을 입력으로 곡 전체를 예측. 만약 중간에 틀린 부분이 생긴다면, 이후 음정, 박자는 모두 이상하게 될 가능성 존재.\n",
        "\n",
        "-> 처음 윈도우사이즈(4개)만 사용해서 다음 5번째 음정을 예측, 그리고 슬라이딩 윈도우 사용해서 결국엔 예측값들만으로 다음 음정을 예측하는 방법.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42EIZmVe1R_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1~4번째 음표를 데이터로 5번째 음표를 라벨값으로 학습. 끝까지 이렇게 반복.\n",
        "\n",
        "\n",
        "# 입력(X)과 출력(Y) 변수로 분리하기\n",
        "mlp_x_train = dataset[:,0:4]   #  학습필요.  행 : 전체, 로우 : 0,1,2,3 가져옴.\n",
        "mlp_y_train = dataset[:,4]     #  학습필요   행 : 전체, 로우 : 4번째 만 가져옴.\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ZSPIJoCs4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c325b908-1c68-429d-852b-f43f48e3d504"
      },
      "source": [
        "print(mlp_x_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 9  7  8  9]\n",
            " [ 7  8  9  7]\n",
            " [ 8  9  7  8]\n",
            " [ 9  7  8 10]\n",
            " [ 7  8 10  3]\n",
            " [ 8 10  3  1]\n",
            " [10  3  1  3]\n",
            " [ 3  1  3  5]\n",
            " [ 1  3  5  7]\n",
            " [ 3  5  7  7]\n",
            " [ 5  7  7  8]\n",
            " [ 7  7  8  6]\n",
            " [ 7  8  6  5]\n",
            " [ 8  6  5  7]\n",
            " [ 6  5  7  6]\n",
            " [ 5  7  6  7]\n",
            " [ 7  6  7  8]\n",
            " [ 6  7  8 10]\n",
            " [ 7  8 10  1]\n",
            " [ 8 10  1 10]\n",
            " [10  1 10  8]\n",
            " [ 1 10  8 10]\n",
            " [10  8 10  5]\n",
            " [ 8 10  5  3]\n",
            " [10  5  3  5]\n",
            " [ 5  3  5  0]\n",
            " [ 3  5  0  5]\n",
            " [ 5  0  5  3]\n",
            " [ 0  5  3  0]\n",
            " [ 5  3  0 10]\n",
            " [ 3  0 10  8]\n",
            " [ 0 10  8 10]\n",
            " [10  8 10  8]\n",
            " [ 8 10  8  7]\n",
            " [10  8  7  8]\n",
            " [ 8  7  8 10]\n",
            " [ 7  8 10  1]\n",
            " [ 8 10  1  3]\n",
            " [10  1  3  5]\n",
            " [ 1  3  5  1]\n",
            " [ 3  5  1  4]\n",
            " [ 5  1  4  3]\n",
            " [ 1  4  3  5]\n",
            " [ 4  3  5  3]\n",
            " [ 3  5  3  5]\n",
            " [ 5  3  5  3]\n",
            " [ 3  5  3  1]\n",
            " [ 5  3  1  3]\n",
            " [ 3  1  3  5]\n",
            " [ 1  3  5  7]\n",
            " [ 3  5  7  7]\n",
            " [ 5  7  7  8]\n",
            " [ 7  7  8 10]\n",
            " [ 7  8 10  9]\n",
            " [ 8 10  9  7]\n",
            " [10  9  7  8]\n",
            " [ 9  7  8  9]\n",
            " [ 7  8  9  7]\n",
            " [ 8  9  7  8]\n",
            " [ 9  7  8 10]\n",
            " [ 7  8 10  3]\n",
            " [ 8 10  3  1]\n",
            " [10  3  1  3]\n",
            " [ 3  1  3  5]\n",
            " [ 1  3  5  7]\n",
            " [ 3  5  7  6]\n",
            " [ 5  7  6  8]\n",
            " [ 7  6  8  7]\n",
            " [ 6  8  7  4]\n",
            " [ 8  7  4  7]\n",
            " [ 7  4  7  7]\n",
            " [ 4  7  7  7]\n",
            " [ 7  7  7  8]\n",
            " [ 7  7  8 10]\n",
            " [ 7  8 10  1]\n",
            " [ 8 10  1 10]\n",
            " [10  1 10  8]\n",
            " [ 1 10  8 10]\n",
            " [10  8 10  5]\n",
            " [ 8 10  5  3]\n",
            " [10  5  3  5]\n",
            " [ 5  3  5  0]\n",
            " [ 3  5  0  5]\n",
            " [ 5  0  5  3]\n",
            " [ 0  5  3  0]\n",
            " [ 5  3  0 10]\n",
            " [ 3  0 10  8]\n",
            " [ 0 10  8 10]\n",
            " [10  8 10  8]\n",
            " [ 8 10  8  7]\n",
            " [10  8  7  8]\n",
            " [ 8  7  8 10]\n",
            " [ 7  8 10  1]\n",
            " [ 8 10  1  2]\n",
            " [10  1  2  5]\n",
            " [ 1  2  5  1]\n",
            " [ 2  5  1  4]\n",
            " [ 5  1  4  1]\n",
            " [ 1  4  1  5]\n",
            " [ 4  1  5  3]\n",
            " [ 1  5  3  5]\n",
            " [ 5  3  5  7]\n",
            " [ 3  5  7  5]\n",
            " [ 5  7  5  3]\n",
            " [ 7  5  3  5]\n",
            " [ 5  3  5  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i37bIJscCmOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7603f3dc-c85a-4c09-87ec-cfedb3733700"
      },
      "source": [
        "\n",
        "max_idx_value = 10   # 총 11개 데이터에서 나눠줘야 하기 때문에 0~10. 최대값인 10으로 나눠졌다.\n",
        "# # 1. 데이터 준비하기. 나온 것들 하나씩 Unique 하게 나열.\n",
        "# 코드 사전 정의\n",
        "# 코드를 숫자로  여기에서 정의된 것들이 0~ 10까지 있다.\n",
        "\n",
        "\n",
        "# 입력값 정규화 시키기\n",
        "mlp_x_train = mlp_x_train / float(max_idx_value)   # 10.0\n",
        "\n",
        "# y값에 대한 라벨값에 대한 one-hot 인코딩 수행 이유 : 구분되야 하는 값이 3개가 넘어가므로 원핫인코딩 해줌. 2개를 안쓰므로 12개로 해줌.\n",
        "mlp_y_train = np_utils.to_categorical(mlp_y_train)\n",
        "\n",
        "one_hot_vec_size = mlp_y_train.shape[1]  # 이 부분은 12라고 정수로 써줘도 무관.\n",
        "\n",
        "print(\"one hot encoding vector size is \", one_hot_vec_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one hot encoding vector size is  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHsMErIpd8iY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6df31d77-c34e-48f6-92b0-28a19a7c6f4f"
      },
      "source": [
        "print(float(max_idx_value))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJsxaWu87JvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ecb92e9-137f-40fd-85fd-9e01a7c154cf"
      },
      "source": [
        "print(mlp_x_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9 0.7 0.8 0.9]\n",
            " [0.7 0.8 0.9 0.7]\n",
            " [0.8 0.9 0.7 0.8]\n",
            " [0.9 0.7 0.8 1. ]\n",
            " [0.7 0.8 1.  0.3]\n",
            " [0.8 1.  0.3 0.1]\n",
            " [1.  0.3 0.1 0.3]\n",
            " [0.3 0.1 0.3 0.5]\n",
            " [0.1 0.3 0.5 0.7]\n",
            " [0.3 0.5 0.7 0.7]\n",
            " [0.5 0.7 0.7 0.8]\n",
            " [0.7 0.7 0.8 0.6]\n",
            " [0.7 0.8 0.6 0.5]\n",
            " [0.8 0.6 0.5 0.7]\n",
            " [0.6 0.5 0.7 0.6]\n",
            " [0.5 0.7 0.6 0.7]\n",
            " [0.7 0.6 0.7 0.8]\n",
            " [0.6 0.7 0.8 1. ]\n",
            " [0.7 0.8 1.  0.1]\n",
            " [0.8 1.  0.1 1. ]\n",
            " [1.  0.1 1.  0.8]\n",
            " [0.1 1.  0.8 1. ]\n",
            " [1.  0.8 1.  0.5]\n",
            " [0.8 1.  0.5 0.3]\n",
            " [1.  0.5 0.3 0.5]\n",
            " [0.5 0.3 0.5 0. ]\n",
            " [0.3 0.5 0.  0.5]\n",
            " [0.5 0.  0.5 0.3]\n",
            " [0.  0.5 0.3 0. ]\n",
            " [0.5 0.3 0.  1. ]\n",
            " [0.3 0.  1.  0.8]\n",
            " [0.  1.  0.8 1. ]\n",
            " [1.  0.8 1.  0.8]\n",
            " [0.8 1.  0.8 0.7]\n",
            " [1.  0.8 0.7 0.8]\n",
            " [0.8 0.7 0.8 1. ]\n",
            " [0.7 0.8 1.  0.1]\n",
            " [0.8 1.  0.1 0.3]\n",
            " [1.  0.1 0.3 0.5]\n",
            " [0.1 0.3 0.5 0.1]\n",
            " [0.3 0.5 0.1 0.4]\n",
            " [0.5 0.1 0.4 0.3]\n",
            " [0.1 0.4 0.3 0.5]\n",
            " [0.4 0.3 0.5 0.3]\n",
            " [0.3 0.5 0.3 0.5]\n",
            " [0.5 0.3 0.5 0.3]\n",
            " [0.3 0.5 0.3 0.1]\n",
            " [0.5 0.3 0.1 0.3]\n",
            " [0.3 0.1 0.3 0.5]\n",
            " [0.1 0.3 0.5 0.7]\n",
            " [0.3 0.5 0.7 0.7]\n",
            " [0.5 0.7 0.7 0.8]\n",
            " [0.7 0.7 0.8 1. ]\n",
            " [0.7 0.8 1.  0.9]\n",
            " [0.8 1.  0.9 0.7]\n",
            " [1.  0.9 0.7 0.8]\n",
            " [0.9 0.7 0.8 0.9]\n",
            " [0.7 0.8 0.9 0.7]\n",
            " [0.8 0.9 0.7 0.8]\n",
            " [0.9 0.7 0.8 1. ]\n",
            " [0.7 0.8 1.  0.3]\n",
            " [0.8 1.  0.3 0.1]\n",
            " [1.  0.3 0.1 0.3]\n",
            " [0.3 0.1 0.3 0.5]\n",
            " [0.1 0.3 0.5 0.7]\n",
            " [0.3 0.5 0.7 0.6]\n",
            " [0.5 0.7 0.6 0.8]\n",
            " [0.7 0.6 0.8 0.7]\n",
            " [0.6 0.8 0.7 0.4]\n",
            " [0.8 0.7 0.4 0.7]\n",
            " [0.7 0.4 0.7 0.7]\n",
            " [0.4 0.7 0.7 0.7]\n",
            " [0.7 0.7 0.7 0.8]\n",
            " [0.7 0.7 0.8 1. ]\n",
            " [0.7 0.8 1.  0.1]\n",
            " [0.8 1.  0.1 1. ]\n",
            " [1.  0.1 1.  0.8]\n",
            " [0.1 1.  0.8 1. ]\n",
            " [1.  0.8 1.  0.5]\n",
            " [0.8 1.  0.5 0.3]\n",
            " [1.  0.5 0.3 0.5]\n",
            " [0.5 0.3 0.5 0. ]\n",
            " [0.3 0.5 0.  0.5]\n",
            " [0.5 0.  0.5 0.3]\n",
            " [0.  0.5 0.3 0. ]\n",
            " [0.5 0.3 0.  1. ]\n",
            " [0.3 0.  1.  0.8]\n",
            " [0.  1.  0.8 1. ]\n",
            " [1.  0.8 1.  0.8]\n",
            " [0.8 1.  0.8 0.7]\n",
            " [1.  0.8 0.7 0.8]\n",
            " [0.8 0.7 0.8 1. ]\n",
            " [0.7 0.8 1.  0.1]\n",
            " [0.8 1.  0.1 0.2]\n",
            " [1.  0.1 0.2 0.5]\n",
            " [0.1 0.2 0.5 0.1]\n",
            " [0.2 0.5 0.1 0.4]\n",
            " [0.5 0.1 0.4 0.1]\n",
            " [0.1 0.4 0.1 0.5]\n",
            " [0.4 0.1 0.5 0.3]\n",
            " [0.1 0.5 0.3 0.5]\n",
            " [0.5 0.3 0.5 0.7]\n",
            " [0.3 0.5 0.7 0.5]\n",
            " [0.5 0.7 0.5 0.3]\n",
            " [0.7 0.5 0.3 0.5]\n",
            " [0.5 0.3 0.5 0.1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu_c0tc26Qu4",
        "colab_type": "text"
      },
      "source": [
        "# 다층 퍼셉트론 모델\n",
        "\n",
        "#입력 속성이 4개(윈도우사이즈) 이고 출력이 11개(one_hot_vec_size=11)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpBgGswR19db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=4, activation='relu'))  # 인풋, 윈도우 사이즈만큼 4개로)\n",
        "dropout = 0.3\n",
        "model.add(Dense(128, activation='relu'))\n",
        "dropout = 0.3\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFHyEx8g1_DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#history = LossHistory() # 손실 이력 객체 생성  #위에 # 손실 이력 클래스 정의 사용.\n",
        "#history.init()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi_JS2mCOpRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "695312b3-8cb1-479c-cc50-c1fda8e2bdc6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               1280      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 11)                1419      \n",
            "=================================================================\n",
            "Total params: 35,595\n",
            "Trainable params: 35,595\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kQG8NAm1rMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f144290c-4394-4545-9e8d-d80491afcd53"
      },
      "source": [
        "model.weights\n",
        "\n",
        "#shape(4,256) -> 한개에서 768개.  X -> 히든레이어로\n",
        "#Shape (256, ) -> 바이어스\n",
        "#shape(256, 128) -> 레이어에서 레이어로\n",
        "#Shape (128, ) -> 바이어스\n",
        "#shape (128, 11) -> 히든레이어에서 y로(출력 레이어)\n",
        "#shape(11, ) -> 히든에서 y로 넘어올 때 보이는 바이어스"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_1/kernel:0' shape=(4, 256) dtype=float32, numpy=\n",
              " array([[-0.10385889,  0.10828912,  0.1336573 , ...,  0.09360293,\n",
              "          0.14877066, -0.12067041],\n",
              "        [-0.06138494,  0.05613537, -0.03769834, ..., -0.1036143 ,\n",
              "         -0.05425702,  0.0361007 ],\n",
              "        [ 0.08481349, -0.05134659,  0.01865812, ..., -0.06340154,\n",
              "         -0.07774098,  0.00072932],\n",
              "        [-0.1293998 , -0.10858741,  0.00364669, ..., -0.12063919,\n",
              "         -0.00864758,  0.12385812]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(256,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_2/kernel:0' shape=(256, 128) dtype=float32, numpy=\n",
              " array([[ 0.05804309, -0.09619018, -0.112113  , ...,  0.05588716,\n",
              "          0.07831225, -0.07842514],\n",
              "        [ 0.0448069 , -0.12287518, -0.06791204, ..., -0.0432356 ,\n",
              "          0.05701688,  0.10884038],\n",
              "        [ 0.03751147, -0.05637705, -0.08118987, ...,  0.12484956,\n",
              "         -0.05124736, -0.12382472],\n",
              "        ...,\n",
              "        [-0.02415663,  0.0411092 , -0.04363078, ..., -0.09048864,\n",
              "          0.122518  ,  0.0778566 ],\n",
              "        [ 0.02297577,  0.01798368, -0.06151253, ..., -0.06096026,\n",
              "         -0.09636694, -0.07226062],\n",
              "        [-0.02724445,  0.0805499 , -0.06046563, ..., -0.1041891 ,\n",
              "         -0.04024667, -0.00981703]], dtype=float32)>,\n",
              " <tf.Variable 'dense_2/bias:0' shape=(128,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_3/kernel:0' shape=(128, 11) dtype=float32, numpy=\n",
              " array([[-1.6774081e-01, -1.8174498e-01, -3.9733112e-02, ...,\n",
              "         -7.1915418e-02,  1.4202119e-01, -1.4658113e-01],\n",
              "        [ 1.0619159e-01, -2.0147306e-01, -1.0435148e-01, ...,\n",
              "          1.4276822e-01, -1.4192306e-01, -4.2526960e-02],\n",
              "        [-1.3653013e-01, -4.7346964e-02, -7.3144957e-02, ...,\n",
              "         -2.3779571e-03,  5.0412849e-02, -1.2795162e-01],\n",
              "        ...,\n",
              "        [-2.6552260e-02, -1.6296677e-01,  6.7024514e-02, ...,\n",
              "         -1.5463674e-01,  1.5692325e-01,  7.1804956e-02],\n",
              "        [-4.2097732e-02, -5.0976872e-05,  1.5531002e-01, ...,\n",
              "          1.6416328e-01, -1.6880982e-01, -8.1775561e-02],\n",
              "        [-1.3904619e-01, -9.6863545e-02, -1.1691924e-01, ...,\n",
              "          1.1595754e-01,  5.9890851e-02, -2.3200706e-02]], dtype=float32)>,\n",
              " <tf.Variable 'dense_3/bias:0' shape=(11,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEHVeVGf1rYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "67e98901-1636-4696-e0a7-b674bd7c43ec"
      },
      "source": [
        "# 5. 모델 학습시키기\n",
        "history = model.fit(mlp_x_train, mlp_y_train, epochs=20, batch_size=4, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 84 samples, validate on 22 samples\n",
            "Epoch 1/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.3563 - accuracy: 0.1548 - val_loss: 2.2565 - val_accuracy: 0.1818\n",
            "Epoch 2/20\n",
            "84/84 [==============================] - 0s 434us/step - loss: 2.1971 - accuracy: 0.2857 - val_loss: 2.1665 - val_accuracy: 0.2727\n",
            "Epoch 3/20\n",
            "84/84 [==============================] - 0s 447us/step - loss: 2.1130 - accuracy: 0.2619 - val_loss: 2.1318 - val_accuracy: 0.2727\n",
            "Epoch 4/20\n",
            "84/84 [==============================] - 0s 412us/step - loss: 2.0584 - accuracy: 0.3214 - val_loss: 2.1016 - val_accuracy: 0.2727\n",
            "Epoch 5/20\n",
            "84/84 [==============================] - 0s 479us/step - loss: 2.0185 - accuracy: 0.2619 - val_loss: 2.0987 - val_accuracy: 0.2727\n",
            "Epoch 6/20\n",
            "84/84 [==============================] - 0s 414us/step - loss: 1.9960 - accuracy: 0.2619 - val_loss: 2.1222 - val_accuracy: 0.2273\n",
            "Epoch 7/20\n",
            "84/84 [==============================] - 0s 424us/step - loss: 1.9434 - accuracy: 0.3214 - val_loss: 2.0686 - val_accuracy: 0.3636\n",
            "Epoch 8/20\n",
            "84/84 [==============================] - 0s 425us/step - loss: 1.9218 - accuracy: 0.2857 - val_loss: 2.0701 - val_accuracy: 0.3182\n",
            "Epoch 9/20\n",
            "84/84 [==============================] - 0s 419us/step - loss: 1.8848 - accuracy: 0.3452 - val_loss: 2.0585 - val_accuracy: 0.3182\n",
            "Epoch 10/20\n",
            "84/84 [==============================] - 0s 417us/step - loss: 1.8486 - accuracy: 0.3690 - val_loss: 2.0647 - val_accuracy: 0.3182\n",
            "Epoch 11/20\n",
            "84/84 [==============================] - 0s 414us/step - loss: 1.8085 - accuracy: 0.3810 - val_loss: 2.0488 - val_accuracy: 0.3182\n",
            "Epoch 12/20\n",
            "84/84 [==============================] - 0s 404us/step - loss: 1.7978 - accuracy: 0.3690 - val_loss: 2.0424 - val_accuracy: 0.2727\n",
            "Epoch 13/20\n",
            "84/84 [==============================] - 0s 414us/step - loss: 1.7725 - accuracy: 0.3810 - val_loss: 2.0664 - val_accuracy: 0.3182\n",
            "Epoch 14/20\n",
            "84/84 [==============================] - 0s 535us/step - loss: 1.7630 - accuracy: 0.4048 - val_loss: 2.0306 - val_accuracy: 0.3182\n",
            "Epoch 15/20\n",
            "84/84 [==============================] - 0s 426us/step - loss: 1.7086 - accuracy: 0.3929 - val_loss: 2.0497 - val_accuracy: 0.2727\n",
            "Epoch 16/20\n",
            "84/84 [==============================] - 0s 482us/step - loss: 1.6923 - accuracy: 0.4048 - val_loss: 2.0655 - val_accuracy: 0.3182\n",
            "Epoch 17/20\n",
            "84/84 [==============================] - 0s 459us/step - loss: 1.6810 - accuracy: 0.4048 - val_loss: 2.0463 - val_accuracy: 0.3182\n",
            "Epoch 18/20\n",
            "84/84 [==============================] - 0s 409us/step - loss: 1.6299 - accuracy: 0.4762 - val_loss: 2.0441 - val_accuracy: 0.2727\n",
            "Epoch 19/20\n",
            "84/84 [==============================] - 0s 406us/step - loss: 1.6283 - accuracy: 0.4167 - val_loss: 2.0302 - val_accuracy: 0.3182\n",
            "Epoch 20/20\n",
            "84/84 [==============================] - 0s 453us/step - loss: 1.6178 - accuracy: 0.4286 - val_loss: 2.0553 - val_accuracy: 0.3182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3NHuMcY2FSU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e8d790f7-b0d8-4c20-fe89-ebd0b3b73072"
      },
      "source": [
        "# 6. 모델 평가하기\n",
        "scores = model.evaluate(mlp_x_train, mlp_y_train)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106/106 [==============================] - 0s 60us/step\n",
            "accuracy: 43.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgtYRMSF1_59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "9d131b3b-34f0-4997-9807-5fee8274c5a5"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', color='red',label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# loss 그래프를 살펴보면 Training loss는 점점 하락.\n",
        "# 하지만 Vaildation loss는 높으므로 좋은 모델이 아님, epochs 향상 필요.\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIQ8D9je2HuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7. 모델 사용하기\n",
        "\n",
        "pred_count = 106 # 최대 예측 개수 정의"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z79hjqB2JhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b4e14cdf-60ed-4b4d-eef7-7199909958d0"
      },
      "source": [
        "# 한 스텝 예측\n",
        "\n",
        "one_step_seq_out = ['g4','e8','f8','g4']\n",
        "pred_out = model.predict(mlp_x_train)\n",
        "\n",
        "for i in range(pred_count):\n",
        "    idx = np.argmax(pred_out[i]) # 인덱스의 최대값을 뽑아옴. \n",
        "    one_step_seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n",
        "    \n",
        "print(\"one step prediction : \", one_step_seq_out)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one step prediction :  ['g4', 'e8', 'f8', 'g4', 'e8', 'e8', 'e8', 'e8', 'g8', 'c8', 'c8', 'e8', 'e8', 'e8', 'f8', 'e8', 'b8', 'e8', 'e8', 'f8', 'e8', 'e8', 'g8', 'f8', 'g8', 'f8', 'g8', 'c8', 'c8', 'c8', 'b8', 'a4', 'b8', 'f8', 'g8', 'f8', 'e8', 'f8', 'e8', 'e8', 'g8', 'c8', 'a4', 'g8', 'b8', 'a4', 'f8', 'c8', 'f8', 'c8', 'c8', 'c8', 'e8', 'e8', 'e8', 'f8', 'e8', 'e8', 'f8', 'e8', 'e8', 'e8', 'e8', 'e8', 'g8', 'c8', 'c8', 'e8', 'e8', 'e8', 'f8', 'e8', 'b8', 'e8', 'e8', 'f8', 'e8', 'e8', 'g8', 'f8', 'g8', 'f8', 'g8', 'c8', 'c8', 'c8', 'b8', 'a4', 'b8', 'f8', 'g8', 'f8', 'e8', 'f8', 'e8', 'e8', 'g8', 'c8', 'a4', 'g8', 'b8', 'c8', 'f8', 'g8', 'f8', 'e8', 'e8', 'b8', 'c8', 'c8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AccU8sc6iDqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb0b0282-26da-4f6e-c2ce-4dd63680f9d9"
      },
      "source": [
        "print(idx)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2AcK75rhtdW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bc7379d3-0ba2-4c75-cae1-c25a6f4eacbe"
      },
      "source": [
        "print(pred_out[i])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.11963883 0.09281344 0.00182104 0.14738292 0.02792251 0.38800636\n",
            " 0.00790973 0.04883266 0.01092283 0.01147489 0.14327478]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiGnNUUnLwIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "55ec7b36-5545-4839-de43-3b95cebf1ae0"
      },
      "source": [
        "# 곡 전체 예측\n",
        "\n",
        "seq_in = ['g4','e8','f8','g4']\n",
        "full_seq_out = seq_in\n",
        "seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n",
        "\n",
        "for i in range(pred_count):\n",
        "    sample_in = np.array(seq_in)  # [0.9 0.7 0.8 0.9]\n",
        "    sample_in = np.reshape(sample_in, (1, 4)) # [[0.9 0.7 0.8 0.9]], batch_size, feature\n",
        "    pred_out = model.predict(sample_in) # [[0.9 0.7 0.8 0.9]] 이것만 갖고 예측하도록 만든 곳......\n",
        "    idx = np.argmax(pred_out)  # 10\n",
        "    full_seq_out.append(idx2code[idx]) \n",
        "    seq_in.append(idx / float(max_idx_value))  # 10/10.0\n",
        "    seq_in.pop(0)\n",
        "   \n",
        "print(\"full song prediction : \", full_seq_out)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "full song prediction :  ['g4', 'e8', 'f8', 'g4', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK4ZmHw-f-7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b85b9ebe-9c14-4f75-c00d-091810f4da60"
      },
      "source": [
        "print(full_seq_out)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['g4', 'e8', 'f8', 'g4', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdlz3Iii2LPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e763c50-c808-4734-efae-16d6742e60cc"
      },
      "source": [
        "print(idx)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMyabJ4RnIu1",
        "colab_type": "text"
      },
      "source": [
        "**Vanilla RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrrUrYFBnM4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import SimpleRNN, Activation, LSTM, Flatten, GRU"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBTyakPcterg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc0ec0da-dc36-4e42-df62-bb8d6a897857"
      },
      "source": [
        "srnn_x_train = dataset[:,0:4]   #  학습필요.  행 : 전체, 로우 : 0,1,2,3 가져옴.\n",
        "srnn_y_train = dataset[:,4] \n",
        "\n",
        "\n",
        "\n",
        "# 입력값 정규화 시키기\n",
        "srnn_x_train = srnn_x_train / float(max_idx_value)   # 10.0\n",
        "\n",
        "\n",
        "\n",
        "# 입력을 (샘플 수, 타입스텝, 특성 수)로 형태 변환\n",
        "srnn_x_train = np.reshape(srnn_x_train, (106, 4, 1)) # 정말 중요 !!!!\n",
        "# 정말 중요 !!!!\n",
        "\n",
        "# y값에 대한 라벨값에 대한 one-hot 인코딩 수행 이유 : 구분되야 하는 값이 3개가 넘어가므로 원핫인코딩 해줌. 2개를 안쓰므로 12개로 해줌.\n",
        "srnn_y_train = np_utils.to_categorical(srnn_y_train)\n",
        "\n",
        "one_hot_vec_size = srnn_y_train.shape[1]  # 이 부분은 12라고 정수로 써줘도 무관.\n",
        "\n",
        "print(\"one hot encoding vector size is \", one_hot_vec_size)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one hot encoding vector size is  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5sXikRlnXYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(256, input_shape = (4, 1)))\n",
        "Dropout = 0.3\n",
        "#model.add(SimpleRNN(128))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "Dropout = 0.3\n",
        "#model.add(Flatten())\n",
        "#model.add(Flatten())\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozeaXU_vn1oK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7tMZG2vn3Ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a7aaa9c1-50c4-469c-a249-8d1359ebaf6c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 256)               66048     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 11)                1419      \n",
            "=================================================================\n",
            "Total params: 100,363\n",
            "Trainable params: 100,363\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSfW1xhV2SVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77607671-7555-4eb2-e83c-2a401ba5957b"
      },
      "source": [
        "model.weights\n",
        "\n",
        "#shape(1,256) -> 한개에서 768개.  X -> 히든레이어로\n",
        "#shape(256, 256) -> 레이어에서 레이어로\n",
        "#Shape (256, ) -> 바이어스\n",
        "#shape(256, 128) -> 레이어에서 레이어로\n",
        "#Shape (128, ) -> 바이어스\n",
        "#shape (128, 11) -> 히든레이어에서 y로(출력 레이어)\n",
        "#shape(11, ) -> 히든에서 y로 넘어올 때 보이는 바이어스"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'simple_rnn_1/kernel:0' shape=(1, 256) dtype=float32, numpy=\n",
              " array([[ 0.06210589,  0.00125262, -0.12381008,  0.03672817,  0.0069042 ,\n",
              "         -0.01996759, -0.02706859, -0.10772955, -0.09948017, -0.11549333,\n",
              "         -0.01600592,  0.01279753,  0.09837188,  0.11697493, -0.00057343,\n",
              "         -0.11472009, -0.02909149, -0.03065481,  0.13671212,  0.14357458,\n",
              "         -0.00746346,  0.07902469,  0.03318854, -0.07542232,  0.00610994,\n",
              "         -0.07006796, -0.0470762 ,  0.11211435, -0.00040993,  0.00651182,\n",
              "         -0.00994895,  0.0264958 ,  0.08332762,  0.01025364,  0.04929732,\n",
              "         -0.13862355,  0.07254668,  0.12253888,  0.14343245, -0.04089402,\n",
              "          0.08652581,  0.01854178, -0.06649029, -0.05897418,  0.11849611,\n",
              "         -0.06403693,  0.08671823,  0.11704554,  0.03896317,  0.13329928,\n",
              "         -0.02817643, -0.131205  ,  0.14830323,  0.10093777,  0.15016712,\n",
              "          0.05305648, -0.0509743 , -0.11242145,  0.09321919,  0.04121985,\n",
              "          0.01912925, -0.07333653,  0.04430439, -0.09867537,  0.12860681,\n",
              "          0.08345352, -0.04159882,  0.03249222, -0.09926265, -0.05935235,\n",
              "          0.02407742, -0.13101244, -0.12718396, -0.02917903, -0.0151459 ,\n",
              "         -0.08710092, -0.13791043,  0.10882269,  0.09186964,  0.12615313,\n",
              "         -0.01913162, -0.03163476,  0.12024696,  0.0351188 ,  0.02244674,\n",
              "         -0.03764123, -0.02983038, -0.04429822, -0.1389096 , -0.09662219,\n",
              "         -0.05951355, -0.05218725,  0.11704196, -0.12178104, -0.01296058,\n",
              "         -0.01754096, -0.06711202,  0.00018211, -0.05429151, -0.12949426,\n",
              "          0.1291462 ,  0.12267964, -0.14175802,  0.06679672,  0.05962689,\n",
              "          0.08272167, -0.13497007,  0.14718287,  0.06255801,  0.05911542,\n",
              "         -0.05678355, -0.04033845,  0.10317795, -0.12178636, -0.02849118,\n",
              "          0.09665158,  0.07463497,  0.10013293,  0.09983422,  0.12249874,\n",
              "          0.02244543,  0.09996916,  0.09578949, -0.1048554 , -0.07405856,\n",
              "          0.11076619,  0.02113897,  0.01715115,  0.02084094,  0.08637588,\n",
              "         -0.07017626, -0.02101147,  0.14710815,  0.0601978 , -0.04274113,\n",
              "         -0.06380644, -0.04229262,  0.13193892,  0.03258373,  0.03530139,\n",
              "         -0.10699357, -0.01551682, -0.04834503, -0.00474945,  0.13261946,\n",
              "          0.0425141 ,  0.07580449,  0.09494495,  0.05227114, -0.12339219,\n",
              "         -0.13761935,  0.1504936 , -0.03982793,  0.00652909, -0.00566943,\n",
              "          0.14688496, -0.11029343,  0.09358837, -0.11550099,  0.11274435,\n",
              "          0.08488901, -0.10096931,  0.12948065,  0.0531822 ,  0.11747675,\n",
              "          0.08099736, -0.1503051 ,  0.1082129 , -0.06682748,  0.0192358 ,\n",
              "          0.14678763, -0.1130454 , -0.04282754, -0.04307282, -0.1512008 ,\n",
              "         -0.14376625,  0.04457818, -0.12926228, -0.06605496, -0.06094802,\n",
              "         -0.10879011, -0.07563757, -0.03500168,  0.07967661, -0.10360843,\n",
              "         -0.13346271, -0.13510104,  0.02808157,  0.07204388, -0.01561145,\n",
              "         -0.10824149,  0.14786674, -0.09930655,  0.09104627,  0.10758047,\n",
              "         -0.10820808,  0.01035623,  0.01438034,  0.02599618,  0.06174368,\n",
              "         -0.0315031 , -0.08454658, -0.08789843,  0.09111618,  0.07365134,\n",
              "          0.0170131 ,  0.11672319,  0.01361205, -0.01354502, -0.02029034,\n",
              "         -0.00535844,  0.11186589,  0.00498115,  0.05892195,  0.1129076 ,\n",
              "         -0.08045671, -0.0586363 ,  0.1523592 , -0.05350813,  0.0744364 ,\n",
              "          0.12637974,  0.10574605,  0.09513628, -0.15107886, -0.09476186,\n",
              "          0.03083554,  0.13387607, -0.05393126,  0.13853969,  0.03534183,\n",
              "          0.04477595, -0.02153014,  0.09257856,  0.03679283,  0.12885611,\n",
              "         -0.06401223,  0.10115208, -0.14266151,  0.05440524,  0.00678195,\n",
              "         -0.09055258, -0.10927043, -0.11861622,  0.11753304, -0.10812367,\n",
              "          0.0458661 ,  0.05254775,  0.05531058, -0.13589767,  0.07017447,\n",
              "          0.06438705, -0.09336349,  0.07315601, -0.04859832, -0.03683881,\n",
              "          0.0631891 ]], dtype=float32)>,\n",
              " <tf.Variable 'simple_rnn_1/recurrent_kernel:0' shape=(256, 256) dtype=float32, numpy=\n",
              " array([[-0.01767028, -0.02020499,  0.04398125, ...,  0.03450212,\n",
              "         -0.07696857,  0.11784062],\n",
              "        [ 0.03180362, -0.06090524,  0.04249664, ..., -0.10607839,\n",
              "         -0.06038615, -0.00716349],\n",
              "        [ 0.09898089,  0.02926582,  0.0957093 , ...,  0.01480164,\n",
              "         -0.01105598,  0.01555033],\n",
              "        ...,\n",
              "        [ 0.046848  , -0.02715925, -0.04257813, ..., -0.07462113,\n",
              "         -0.11121521, -0.02172797],\n",
              "        [-0.03161575,  0.04439019,  0.03077414, ..., -0.1299444 ,\n",
              "          0.06782437, -0.04837541],\n",
              "        [ 0.02202601,  0.03187679,  0.03606492, ...,  0.00467331,\n",
              "         -0.01194874, -0.05025697]], dtype=float32)>,\n",
              " <tf.Variable 'simple_rnn_1/bias:0' shape=(256,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_4/kernel:0' shape=(256, 128) dtype=float32, numpy=\n",
              " array([[ 0.06242117,  0.10337573, -0.07047287, ..., -0.07579494,\n",
              "          0.04658559,  0.09920359],\n",
              "        [-0.02371708,  0.08605033,  0.11940289, ...,  0.06997907,\n",
              "          0.10364413, -0.04234791],\n",
              "        [ 0.04220662,  0.00887164, -0.00036284, ...,  0.04365745,\n",
              "          0.01511362, -0.01091832],\n",
              "        ...,\n",
              "        [ 0.0487923 , -0.11308953,  0.11478403, ..., -0.04514569,\n",
              "         -0.07524404, -0.11099482],\n",
              "        [ 0.10715556,  0.03709313,  0.03382865, ...,  0.09560686,\n",
              "          0.01780686,  0.00967348],\n",
              "        [ 0.07189736,  0.00307178, -0.09032914, ..., -0.1080485 ,\n",
              "          0.05428934,  0.08124259]], dtype=float32)>,\n",
              " <tf.Variable 'dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_5/kernel:0' shape=(128, 11) dtype=float32, numpy=\n",
              " array([[ 0.17948164, -0.17336105,  0.10413007, ..., -0.06333672,\n",
              "         -0.02796321,  0.1180851 ],\n",
              "        [ 0.20595281,  0.15762664, -0.08946536, ..., -0.17155354,\n",
              "         -0.11727653,  0.1342556 ],\n",
              "        [ 0.08528753,  0.07855959,  0.12826969, ...,  0.1632557 ,\n",
              "         -0.11377212,  0.16359557],\n",
              "        ...,\n",
              "        [-0.08091509,  0.09743972, -0.09387399, ..., -0.16031855,\n",
              "         -0.20626973, -0.15540864],\n",
              "        [-0.11198996, -0.01745029, -0.10321967, ..., -0.16405147,\n",
              "          0.07967784, -0.15719926],\n",
              "        [ 0.13238348,  0.11642276, -0.07879621, ..., -0.20077422,\n",
              "          0.10225733,  0.09487547]], dtype=float32)>,\n",
              " <tf.Variable 'dense_5/bias:0' shape=(11,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Om2AH92Sd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "0b14d135-4592-48f1-80eb-a84eaa626c60"
      },
      "source": [
        "history = model.fit(srnn_x_train, srnn_y_train, epochs=20, batch_size=10, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 84 samples, validate on 22 samples\n",
            "Epoch 1/20\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 2.3378 - accuracy: 0.1190 - val_loss: 2.1557 - val_accuracy: 0.3636\n",
            "Epoch 2/20\n",
            "84/84 [==============================] - 0s 570us/step - loss: 2.1600 - accuracy: 0.2262 - val_loss: 2.1180 - val_accuracy: 0.2273\n",
            "Epoch 3/20\n",
            "84/84 [==============================] - 0s 537us/step - loss: 2.0767 - accuracy: 0.2262 - val_loss: 2.1556 - val_accuracy: 0.1364\n",
            "Epoch 4/20\n",
            "84/84 [==============================] - 0s 532us/step - loss: 2.0498 - accuracy: 0.1905 - val_loss: 2.1276 - val_accuracy: 0.0909\n",
            "Epoch 5/20\n",
            "84/84 [==============================] - 0s 545us/step - loss: 1.9958 - accuracy: 0.2262 - val_loss: 2.1513 - val_accuracy: 0.2273\n",
            "Epoch 6/20\n",
            "84/84 [==============================] - 0s 519us/step - loss: 1.9514 - accuracy: 0.3333 - val_loss: 2.1110 - val_accuracy: 0.1364\n",
            "Epoch 7/20\n",
            "84/84 [==============================] - 0s 511us/step - loss: 1.9270 - accuracy: 0.2738 - val_loss: 2.1375 - val_accuracy: 0.2727\n",
            "Epoch 8/20\n",
            "84/84 [==============================] - 0s 514us/step - loss: 1.9813 - accuracy: 0.1667 - val_loss: 2.1839 - val_accuracy: 0.1364\n",
            "Epoch 9/20\n",
            "84/84 [==============================] - 0s 509us/step - loss: 1.9245 - accuracy: 0.2857 - val_loss: 2.1598 - val_accuracy: 0.2273\n",
            "Epoch 10/20\n",
            "84/84 [==============================] - 0s 498us/step - loss: 1.9079 - accuracy: 0.3214 - val_loss: 2.1705 - val_accuracy: 0.1364\n",
            "Epoch 11/20\n",
            "84/84 [==============================] - 0s 595us/step - loss: 1.8218 - accuracy: 0.3452 - val_loss: 2.1294 - val_accuracy: 0.1364\n",
            "Epoch 12/20\n",
            "84/84 [==============================] - 0s 501us/step - loss: 1.8019 - accuracy: 0.3929 - val_loss: 2.1252 - val_accuracy: 0.2273\n",
            "Epoch 13/20\n",
            "84/84 [==============================] - 0s 497us/step - loss: 1.7928 - accuracy: 0.4167 - val_loss: 2.1671 - val_accuracy: 0.1364\n",
            "Epoch 14/20\n",
            "84/84 [==============================] - 0s 505us/step - loss: 1.7656 - accuracy: 0.3452 - val_loss: 2.1366 - val_accuracy: 0.1818\n",
            "Epoch 15/20\n",
            "84/84 [==============================] - 0s 592us/step - loss: 1.7358 - accuracy: 0.4762 - val_loss: 2.1512 - val_accuracy: 0.2273\n",
            "Epoch 16/20\n",
            "84/84 [==============================] - 0s 539us/step - loss: 1.7345 - accuracy: 0.3214 - val_loss: 2.1370 - val_accuracy: 0.2273\n",
            "Epoch 17/20\n",
            "84/84 [==============================] - 0s 506us/step - loss: 1.7154 - accuracy: 0.3929 - val_loss: 2.2171 - val_accuracy: 0.2727\n",
            "Epoch 18/20\n",
            "84/84 [==============================] - 0s 493us/step - loss: 1.7051 - accuracy: 0.3452 - val_loss: 2.1277 - val_accuracy: 0.1818\n",
            "Epoch 19/20\n",
            "84/84 [==============================] - 0s 488us/step - loss: 1.6834 - accuracy: 0.3690 - val_loss: 2.1409 - val_accuracy: 0.2727\n",
            "Epoch 20/20\n",
            "84/84 [==============================] - 0s 509us/step - loss: 1.6125 - accuracy: 0.4286 - val_loss: 2.1978 - val_accuracy: 0.2273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz3YEJIbzbAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "16d10513-247d-4fe4-bbb8-b74adc6412a7"
      },
      "source": [
        "scores = model.evaluate(srnn_x_train, srnn_y_train)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106/106 [==============================] - 0s 79us/step\n",
            "accuracy: 35.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mid52Dpx2iQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "de2c1891-6257-4143-8d1c-e34e7332f3bd"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', color='red',label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# loss 그래프를 살펴보면 Training loss는 점점 하락.\n",
        "# 하지만 Vaildation loss는 높아지는 것을 봤을 때 과적합인것을 의심 가능. 그러므로  epochs 증가 학습 더 필요."
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4sf2kofn7pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_count = 106 # 최대 예측 개수 정의"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ3Duf0UuQuA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "20e2d295-ff3d-48c9-a338-65f70e31a0ce"
      },
      "source": [
        "# 한 스텝 예측\n",
        "\n",
        "one_step_seq_out = ['g4','e8','f8','g4']\n",
        "pred_out = model.predict(srnn_x_train)\n",
        "\n",
        "for i in range(pred_count):\n",
        "    idx = np.argmax(pred_out[i]) # 인덱스의 최대값을 뽑아옴. \n",
        "    one_step_seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n",
        "    \n",
        "print(\"one step prediction : \", one_step_seq_out)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one step prediction :  ['g4', 'e8', 'f8', 'g4', 'g8', 'g8', 'g8', 'g8', 'g8', 'c8', 'c8', 'e8', 'e8', 'e8', 'f8', 'g8', 'g8', 'e8', 'e8', 'f8', 'g8', 'e8', 'g8', 'f8', 'g8', 'c8', 'g8', 'f8', 'g8', 'g8', 'b8', 'g8', 'g8', 'e8', 'g8', 'c8', 'g8', 'g8', 'g8', 'g8', 'g8', 'c8', 'g8', 'b8', 'b8', 'g8', 'b8', 'e8', 'b8', 'e8', 'b8', 'c8', 'e8', 'e8', 'e8', 'f8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'c8', 'c8', 'e8', 'e8', 'e8', 'f8', 'g8', 'f8', 'e8', 'g8', 'f8', 'e8', 'g8', 'g8', 'f8', 'g8', 'c8', 'g8', 'f8', 'g8', 'g8', 'b8', 'g8', 'g8', 'e8', 'g8', 'c8', 'g8', 'g8', 'g8', 'g8', 'g8', 'c8', 'g8', 'e8', 'b8', 'g8', 'b8', 'g8', 'f8', 'e8', 'e8', 'f8', 'e8', 'e8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjoFv5ruvOgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "85bf365a-1153-44dd-b242-cc16f0be576b"
      },
      "source": [
        "# 곡 전체 예측\n",
        "\n",
        "seq_in = ['g4','e8','f8','g4']\n",
        "full_seq_out = seq_in\n",
        "seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n",
        "\n",
        "for i in range(pred_count):\n",
        "    sample_in = np.array(seq_in)  # [0.9 0.7 0.8 0.9]\n",
        "    sample_in = np.reshape(sample_in, (1, 4, 1)) # [[0.9 0.7 0.8 0.9]], batch_size, feature, attribute\n",
        "    pred_out = model.predict(sample_in) # [[0.9 0.7 0.8 0.9]] 이것만 갖고 예측하도록 만든 곳......\n",
        "    idx = np.argmax(pred_out)  # 10\n",
        "    full_seq_out.append(idx2code[idx]) \n",
        "    seq_in.append(idx / float(max_idx_value))  # 10/10.0\n",
        "    seq_in.pop(0)\n",
        "   \n",
        "print(\"full song prediction : \", full_seq_out)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "full song prediction :  ['g4', 'e8', 'f8', 'g4', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8', 'g8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx2DbqWDvZrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMYx0CBMvi7g",
        "colab_type": "text"
      },
      "source": [
        "Stateful LSTM \n",
        "# 상태유지 모드에서는 현재 샘플의 학습 상태가 다음 샘플의 초기 상태로 전달된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H585YrfHvlkF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d5a5b32-efed-4606-80e4-347aa5191886"
      },
      "source": [
        "slstm_x_train = dataset[:,0:4]   #  학습필요.  행 : 전체, 로우 : 0,1,2,3 가져옴.\n",
        "slstm_y_train = dataset[:,4] \n",
        "\n",
        "\n",
        "# 입력값 정규화 시키기\n",
        "slstm_x_train = slstm_x_train / float(max_idx_value)   # 10.0\n",
        "\n",
        "\n",
        "\n",
        "# 입력을 (샘플 수, 타입스텝, 특성 수)로 형태 변환\n",
        "slstm_x_train = np.reshape(slstm_x_train, (106, 4, 1)) # 정말 중요 !!!!\n",
        "# 정말 중요 !!!!\n",
        "\n",
        "# y값에 대한 라벨값에 대한 one-hot 인코딩 수행 이유 : 구분되야 하는 값이 3개가 넘어가므로 원핫인코딩 해줌. 2개를 안쓰므로 12개로 해줌.\n",
        "slstm_y_train = np_utils.to_categorical(slstm_y_train)\n",
        "\n",
        "one_hot_vec_size = slstm_y_train.shape[1]  # 이 부분은 12라고 정수로 써줘도 무관.\n",
        "\n",
        "print(\"one hot encoding vector size is \", one_hot_vec_size)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one hot encoding vector size is  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKsIXFNfv1LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, batch_input_shape = (1, 4, 1), stateful=True, return_sequences=True))   # 상태유지 LSTM 모델을 생성하기 위해서는 LSTM 레이어 생성 시, stateful=True로 설정\n",
        " # 상태유지 모드에서는 입력형태를 batch_input_shape = (배치사이즈, 타임스텝, 속성)으로 설정\n",
        "dropout=0.3\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "dropout=0.3\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOSN-p8DwB3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MQUwEej2tHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "abb40a4e-d849-4c43-e914-d5c9814fee59"
      },
      "source": [
        "model.weights\n",
        "\n",
        "#shape(1,1024) -> 한개에서 768개.  X -> 히든레이어로\n",
        "#shape(256, 1024) -> 레이어에서 레이어로\n",
        "#Shape (1024, ) -> 바이어스\n",
        "#shape(256, 512) -> 레이어에서 레이어로\n",
        "#shape(128, 512) -> 레이어에서 레이어로 (순환레이어)\n",
        "#Shape (512, ) -> 바이어스\n",
        "#shape (128, 11) -> 히든레이어에서 y로(출력 레이어)\n",
        "#shape(11, ) -> 히든에서 y로 넘어올 때 보이는 바이어스"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'lstm_1/kernel:0' shape=(1, 1024) dtype=float32, numpy=\n",
              " array([[-0.00072067,  0.06937678, -0.06063251, ...,  0.04058098,\n",
              "         -0.06868935, -0.00119077]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_1/recurrent_kernel:0' shape=(256, 1024) dtype=float32, numpy=\n",
              " array([[-0.03766399, -0.01335462, -0.01576716, ...,  0.02129538,\n",
              "          0.01635417,  0.01658975],\n",
              "        [-0.0277096 ,  0.016492  ,  0.01976645, ..., -0.00834349,\n",
              "          0.00172124,  0.01442848],\n",
              "        [-0.02932655,  0.06143856,  0.01811641, ...,  0.00196634,\n",
              "         -0.01864892, -0.01700939],\n",
              "        ...,\n",
              "        [ 0.0476618 , -0.06519192, -0.03247499, ...,  0.01786317,\n",
              "          0.0235286 , -0.02106552],\n",
              "        [-0.04049762, -0.0169132 ,  0.04229394, ...,  0.00625562,\n",
              "          0.02278994, -0.02076214],\n",
              "        [ 0.02384838,  0.01727076,  0.02250842, ...,  0.03847176,\n",
              "          0.03300765,  0.05417418]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_1/bias:0' shape=(1024,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'lstm_2/kernel:0' shape=(256, 512) dtype=float32, numpy=\n",
              " array([[-0.02963035, -0.08122686,  0.03441484, ...,  0.02010678,\n",
              "         -0.06090148,  0.03689068],\n",
              "        [ 0.00908338, -0.04071253, -0.03959694, ...,  0.07351605,\n",
              "         -0.03587946, -0.03889806],\n",
              "        [ 0.01664872, -0.07474636, -0.06189658, ..., -0.04527397,\n",
              "          0.00502148,  0.0074302 ],\n",
              "        ...,\n",
              "        [-0.08479419, -0.06965198,  0.04033156, ..., -0.06218605,\n",
              "          0.08766779, -0.04999929],\n",
              "        [-0.08360481, -0.06612105, -0.06868221, ..., -0.01549581,\n",
              "          0.06046694, -0.0619597 ],\n",
              "        [-0.0830828 ,  0.05945597,  0.01653918, ..., -0.0294492 ,\n",
              "          0.0781923 , -0.07970264]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_2/recurrent_kernel:0' shape=(128, 512) dtype=float32, numpy=\n",
              " array([[-1.4771668e-03,  3.3596911e-02, -4.3633547e-02, ...,\n",
              "          4.7106817e-02,  9.1876544e-02,  2.5157545e-02],\n",
              "        [ 3.6362346e-02,  1.2177715e-04,  2.1299968e-02, ...,\n",
              "         -7.1230233e-02,  5.2008359e-03,  1.3908243e-02],\n",
              "        [ 7.4533019e-03, -5.6301970e-02, -4.2187460e-04, ...,\n",
              "         -1.4246485e-02,  4.4157807e-02, -3.2947073e-03],\n",
              "        ...,\n",
              "        [-3.6535878e-02, -2.0330237e-02,  7.3697411e-02, ...,\n",
              "         -1.5348545e-02, -5.5600651e-02, -8.3856463e-02],\n",
              "        [-6.3589183e-03,  2.0517133e-02,  2.9743142e-02, ...,\n",
              "          1.3889714e-01, -3.2056952e-03,  6.5063916e-02],\n",
              "        [-1.2949235e-02, -1.5258158e-03,  7.5947963e-02, ...,\n",
              "         -1.6347529e-02, -4.6982054e-02,  8.1946645e-03]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_2/bias:0' shape=(512,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_6/kernel:0' shape=(128, 11) dtype=float32, numpy=\n",
              " array([[-0.15495327, -0.14886487, -0.03679328, ...,  0.16773681,\n",
              "          0.1158769 , -0.12527151],\n",
              "        [ 0.14860214,  0.10736002, -0.09361304, ..., -0.04248366,\n",
              "          0.01991993, -0.1881594 ],\n",
              "        [ 0.06237714, -0.16291644,  0.20523466, ...,  0.13494174,\n",
              "          0.17802264,  0.2002189 ],\n",
              "        ...,\n",
              "        [-0.04019472,  0.13976805,  0.16506846, ..., -0.10959645,\n",
              "         -0.16839774, -0.02826065],\n",
              "        [-0.19934966,  0.06760179, -0.2047715 , ..., -0.16834687,\n",
              "          0.02889267, -0.00754629],\n",
              "        [-0.04470767,  0.08143972,  0.15851189, ...,  0.08137254,\n",
              "          0.03930622, -0.2022393 ]], dtype=float32)>,\n",
              " <tf.Variable 'dense_6/bias:0' shape=(11,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ycMzrq--JQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "85deaf5f-a12b-4783-f65e-54dbe1c65421"
      },
      "source": [
        "#  현재 샘플과 다음 샘플 간의 순차적인 관계가 없을 경우에는 상태가 유지되지 않고 초기화가 되어야 함. 예를들어......\n",
        " # 1) 마지막 샘플 학습이 마치고, 새로운 에포크 수행 시에는 새로운 샘플 학습을 해야하므로 상태 초기화 필요 (현재 모델에 해당)\n",
        " # 2) 한 에포크 안에 여러 시퀀스 데이터 세트가 있을 경우, 새로운 시퀀스 데이터 세트를 학습 전에 상태 초기화 필요\n",
        " \n",
        "num_epochs = 2\n",
        "\n",
        "for epoch_idx in range(num_epochs):\n",
        "    print ('epochs : ' + str(epoch_idx) )\n",
        "    #model.fit(slstm_x_train, slstm_y_train, epochs=1, batch_size=1, verbose=2, shuffle=False)\n",
        "    history = model.fit(slstm_x_train, slstm_y_train, epochs=1, batch_size=1, verbose=1, shuffle=False, validation_split=0.2)\n",
        "    model.reset_states()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs : 0\n",
            "Train on 84 samples, validate on 22 samples\n",
            "Epoch 1/1\n",
            "84/84 [==============================] - 1s 17ms/step - loss: 2.3335 - accuracy: 0.0833 - val_loss: 2.2355 - val_accuracy: 0.0909\n",
            "epochs : 1\n",
            "Train on 84 samples, validate on 22 samples\n",
            "Epoch 1/1\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.1793 - accuracy: 0.1190 - val_loss: 2.2383 - val_accuracy: 0.0909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLs7BawB3Mf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "72549fad-f108-44c0-a77b-65d7ee66931e"
      },
      "source": [
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', color='red',label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA7vMoU1wx5b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "eb6b403b-6085-4890-850a-3d09063ab8bf"
      },
      "source": [
        "scores = model.evaluate(slstm_x_train, slstm_y_train, batch_size=1)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
        "model.reset_states()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106/106 [==============================] - 0s 1ms/step\n",
            "accuracy: 16.04%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14InSoIBxOTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_count = 106 # 최대 예측 개수 정의"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c1o84bzxFG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2c883fd1-893a-4a88-b7fb-6da589d814d8"
      },
      "source": [
        "one_step_seq_out = ['g4','e8','f8','g4']\n",
        "pred_out = model.predict(slstm_x_train, batch_size=1)\n",
        "\n",
        "for i in range(pred_count):\n",
        "    idx = np.argmax(pred_out[i]) # 인덱스의 최대값을 뽑아옴. \n",
        "    one_step_seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n",
        "\n",
        "model.reset_states()\n",
        "\n",
        "print(\"one step prediction : \", one_step_seq_out)\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one step prediction :  ['g4', 'e8', 'f8', 'g4', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJZXN24lxQie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "00aa6ddb-0e20-4a72-d615-78758db5714f"
      },
      "source": [
        "# 곡 전체 예측\n",
        "\n",
        "seq_in = ['g4','e8','f8','g4']\n",
        "full_seq_out = seq_in\n",
        "seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n",
        "\n",
        "for i in range(pred_count):\n",
        "    sample_in = np.array(seq_in)  # [0.9 0.7 0.8 0.9]\n",
        "    sample_in = np.reshape(sample_in, (1, 4, 1)) # [[0.9 0.7 0.8 0.9]], batch_size, feature, attribute\n",
        "    pred_out = model.predict(sample_in) # [[0.9 0.7 0.8 0.9]] 이것만 갖고 예측하도록 만든 곳......\n",
        "    idx = np.argmax(pred_out)  # 10\n",
        "    full_seq_out.append(idx2code[idx]) \n",
        "    seq_in.append(idx / float(max_idx_value))  # 10/10.0\n",
        "    seq_in.pop(0)\n",
        "   \n",
        "\n",
        "model.reset_states()\n",
        "\n",
        "print(\"full song prediction : \", full_seq_out)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "full song prediction :  ['g4', 'e8', 'f8', 'g4', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8', 'e8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsCLoS0wyMF3",
        "colab_type": "text"
      },
      "source": [
        "# GRU 구현\n",
        "\n",
        "GRU 이해\n",
        "https://it-ist.tistory.com/27"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNg0jeXnyNgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d28d02e-72ce-4d9c-9366-d4979224161a"
      },
      "source": [
        "gru_x_train = dataset[:,0:4]   #  학습필요.  행 : 전체, 로우 : 0,1,2,3 가져옴.\n",
        "gru_y_train = dataset[:,4] \n",
        "\n",
        "\n",
        "# 입력값 정규화 시키기\n",
        "gru_x_train = gru_x_train / float(max_idx_value)   # 10.0\n",
        "\n",
        "\n",
        "\n",
        "# 입력을 (샘플 수, 타입스텝, 특성 수)로 형태 변환\n",
        "gru_x_train = np.reshape(gru_x_train, (106, 4, 1)) # 정말 중요 !!!!\n",
        "# 정말 중요 !!!!\n",
        "\n",
        "# y값에 대한 라벨값에 대한 one-hot 인코딩 수행 이유 : 구분되야 하는 값이 3개가 넘어가므로 원핫인코딩 해줌. 2개를 안쓰므로 12개로 해줌.\n",
        "gru_y_train = np_utils.to_categorical(gru_y_train)\n",
        "\n",
        "one_hot_vec_size = gru_y_train.shape[1]  # 이 부분은 12라고 정수로 써줘도 무관.\n",
        "\n",
        "print(\"one hot encoding vector size is \", one_hot_vec_size)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one hot encoding vector size is  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BQrgqhQyZG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(GRU(256,input_shape = (4, 1))) #GRU를 호출\n",
        "Dropout = 0.3\n",
        "model.add(Dense(128, activation='relu'))\n",
        "Dropout = 0.3\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTgpbD9uyziF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8YmQ9ocy8bt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "10d2f82b-9fe2-4186-af13-c5b554d384c7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_1 (GRU)                  (None, 256)               198144    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 11)                1419      \n",
            "=================================================================\n",
            "Total params: 232,459\n",
            "Trainable params: 232,459\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWQa0ccYzmNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cecfa49e-434a-41a5-acd1-55f2ef64daf4"
      },
      "source": [
        "model.weights\n",
        "\n",
        "#shape(1,768) -> 한개에서 768개.  X -> 히든레이어로\n",
        "#shape(256, 768) -> 레이어에서 레이어로\n",
        "#Shape (768, ) -> 바이어스\n",
        "#shape(256, 128) -> 레이어에서 레이어로\n",
        "#Shape (128, ) -> 바이어스\n",
        "#shape (128, 11) -> 히든레이어에서 y로(출력 레이어)\n",
        "#shape(11, ) -> 히든에서 y로 넘어올 때 보이는 바이어스"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'gru_1/kernel:0' shape=(1, 768) dtype=float32, numpy=\n",
              " array([[ 0.04921014,  0.07220829,  0.06886447, -0.05190243,  0.06971536,\n",
              "         -0.01800396,  0.03188157,  0.08645747, -0.06336058,  0.07779887,\n",
              "         -0.08086405,  0.05243935, -0.07364402, -0.01243888,  0.0159766 ,\n",
              "          0.01309318,  0.02931271,  0.02859196,  0.05644164, -0.02093201,\n",
              "         -0.0715626 , -0.07492268,  0.02453733, -0.01932675, -0.08196156,\n",
              "          0.03755195, -0.03037125, -0.0362368 , -0.02586801,  0.06136083,\n",
              "         -0.05181141,  0.07805369, -0.08147365,  0.07141925, -0.01210925,\n",
              "          0.08480457, -0.03757534,  0.06876255,  0.05324978, -0.02472213,\n",
              "         -0.02049317, -0.05413815, -0.0017724 , -0.04239201,  0.0086778 ,\n",
              "         -0.02512827,  0.02317209, -0.05649667, -0.02691038,  0.04285672,\n",
              "         -0.04826418,  0.08333457,  0.078462  , -0.05748953, -0.021795  ,\n",
              "         -0.06646264, -0.05035709, -0.05375015, -0.06555675, -0.00274084,\n",
              "          0.01198409,  0.06662489,  0.01776031, -0.02372472,  0.06357927,\n",
              "          0.02163347,  0.07255622,  0.03074902, -0.08357918, -0.06859847,\n",
              "         -0.00130345, -0.00657728,  0.01024848, -0.06499345, -0.03179428,\n",
              "          0.05580848,  0.06638729, -0.01898481,  0.07608127,  0.05099542,\n",
              "         -0.05651025, -0.02439657, -0.05568545, -0.00674499,  0.08673746,\n",
              "         -0.04660667, -0.01635131,  0.04413291, -0.00364371,  0.07434847,\n",
              "         -0.08053657,  0.00700798, -0.03703124, -0.07593351, -0.04701496,\n",
              "         -0.0584467 ,  0.03782443,  0.08756968,  0.04113986,  0.05992744,\n",
              "         -0.03595768,  0.07881206, -0.00495076,  0.05095468,  0.07480683,\n",
              "          0.06809076, -0.06465735, -0.06108706, -0.05062221,  0.07760324,\n",
              "          0.07105892, -0.01202493,  0.04138613, -0.00313194, -0.02212014,\n",
              "         -0.06843168,  0.01018109, -0.07082914, -0.01398279,  0.08071364,\n",
              "         -0.00381575, -0.00435418,  0.0464894 ,  0.04678995, -0.06534909,\n",
              "          0.03140684,  0.07433895, -0.02902219,  0.06993312, -0.07827939,\n",
              "          0.02761476,  0.0368866 ,  0.08231058, -0.03780388,  0.02505329,\n",
              "          0.06649785, -0.05143866,  0.07977801,  0.03773042,  0.06826817,\n",
              "          0.0207077 ,  0.03715714,  0.02529813,  0.00802148,  0.0353913 ,\n",
              "          0.06747483,  0.06802564, -0.00740904,  0.00637545,  0.02069064,\n",
              "          0.08418225,  0.06708177,  0.08588096, -0.04850388,  0.07700986,\n",
              "          0.04588937,  0.08462513,  0.06441361, -0.05434161, -0.08329061,\n",
              "          0.08321164, -0.04013982,  0.05334642, -0.04514774, -0.02862083,\n",
              "          0.04225072,  0.05995428, -0.0318714 ,  0.08315156,  0.01780441,\n",
              "          0.02805622,  0.06189961,  0.05531   , -0.02535754, -0.04734262,\n",
              "          0.00054001, -0.00625427,  0.01590581, -0.0883289 , -0.05718233,\n",
              "          0.01407882,  0.05340382,  0.03257557,  0.05022686,  0.02014951,\n",
              "         -0.00808182, -0.03229202,  0.00962181,  0.07677709,  0.00678363,\n",
              "          0.08123828, -0.04859696, -0.00317806, -0.01931416,  0.01734377,\n",
              "          0.04281794,  0.02634141, -0.01329757,  0.06576971, -0.01979554,\n",
              "         -0.04503132, -0.03084194,  0.04410275,  0.07255959,  0.0048705 ,\n",
              "         -0.01070015, -0.06569046, -0.00619943,  0.04863919, -0.04751984,\n",
              "         -0.01312077, -0.00319872,  0.00932942, -0.04137967,  0.06975982,\n",
              "          0.05952934, -0.06906882,  0.08195811,  0.01503449, -0.03201275,\n",
              "         -0.05780046, -0.0038148 ,  0.00013885, -0.04239515,  0.05202544,\n",
              "         -0.02760809,  0.01429354, -0.0074575 , -0.0329711 ,  0.06936366,\n",
              "          0.06065536,  0.01134948,  0.01149426, -0.05510511, -0.0810746 ,\n",
              "          0.06788958, -0.04476567,  0.06044989,  0.02031968, -0.0167266 ,\n",
              "          0.00443046, -0.04826841, -0.06749892, -0.01253182,  0.05402128,\n",
              "          0.00028538,  0.02577659, -0.07304001,  0.00941951,  0.04444946,\n",
              "         -0.07002658, -0.08309695,  0.03810088, -0.04795068, -0.07439911,\n",
              "         -0.04970668,  0.04680649,  0.02673988, -0.06872464, -0.00532716,\n",
              "          0.05782592,  0.00011562,  0.04025758,  0.06553975, -0.06534944,\n",
              "          0.06057823, -0.07677928, -0.01920061,  0.05648042, -0.02719275,\n",
              "         -0.02242957,  0.06455471,  0.04828847, -0.04782095, -0.01612309,\n",
              "         -0.06372295, -0.05240209,  0.027801  , -0.02063265, -0.00584386,\n",
              "         -0.07432697, -0.07660188, -0.03574257,  0.03972263,  0.01820526,\n",
              "          0.00758243,  0.06294181,  0.06424867, -0.05279829, -0.00457038,\n",
              "         -0.03977833,  0.01925966, -0.06739383, -0.03851776,  0.05851591,\n",
              "         -0.00453325,  0.02643967,  0.00380199, -0.02393734,  0.07292003,\n",
              "          0.08407102,  0.01335563,  0.0466729 , -0.07448736, -0.05635648,\n",
              "         -0.04349885,  0.07671472, -0.0743487 , -0.03512729,  0.08632012,\n",
              "          0.05356803, -0.06057316,  0.03555849,  0.00192905, -0.06335352,\n",
              "         -0.01725033,  0.04053325, -0.05296854,  0.05681964, -0.08401934,\n",
              "          0.08202177, -0.07775302, -0.07871318,  0.05946999,  0.04681767,\n",
              "          0.06017736, -0.05985161,  0.0326422 , -0.00407491, -0.02908317,\n",
              "         -0.03339254,  0.07718908, -0.04354592,  0.00601312,  0.06706742,\n",
              "          0.01141879, -0.01527552, -0.06055418, -0.07623357,  0.03989523,\n",
              "         -0.02059519, -0.02756218, -0.08495142, -0.06383674, -0.04527565,\n",
              "         -0.04615153, -0.07454864,  0.07578702,  0.07772063,  0.01977364,\n",
              "          0.00441102, -0.01109409, -0.07182293, -0.00670316,  0.07376935,\n",
              "          0.04871867,  0.07485858, -0.03181155,  0.01530614, -0.07584172,\n",
              "         -0.05049345, -0.06641401,  0.00797535,  0.03006513,  0.08690801,\n",
              "         -0.05024027,  0.0330869 ,  0.05042876,  0.04269642, -0.00356928,\n",
              "          0.05180965,  0.01300318, -0.02694433, -0.03833861,  0.0561899 ,\n",
              "         -0.06371264, -0.03939298,  0.04276998,  0.07349613, -0.03494738,\n",
              "          0.03857226, -0.07182831, -0.06598432,  0.06192674,  0.01481848,\n",
              "         -0.06493799,  0.08746926, -0.02832919,  0.05385762,  0.05791768,\n",
              "          0.00585458, -0.05420986, -0.06395729, -0.07085446,  0.0253245 ,\n",
              "         -0.08646802,  0.03808237, -0.08543742, -0.06573639, -0.04756746,\n",
              "          0.03063854, -0.00467756,  0.03261776,  0.00476228,  0.03470463,\n",
              "         -0.08676685,  0.03982014, -0.05534334,  0.02877006,  0.07778341,\n",
              "          0.00763223,  0.04185314, -0.01281027, -0.08745143, -0.00479932,\n",
              "         -0.04307618, -0.06957029,  0.04893177,  0.03961087,  0.02955053,\n",
              "         -0.04505889,  0.06958445,  0.06020605,  0.06957366, -0.06907111,\n",
              "         -0.02297327,  0.05811127, -0.08715122,  0.05549596, -0.00392446,\n",
              "         -0.05840557,  0.06829048,  0.00921582, -0.06811439, -0.00525686,\n",
              "          0.04760591, -0.05638596, -0.08101816,  0.05467869, -0.03570111,\n",
              "         -0.03952812, -0.07564343, -0.04258155, -0.04098411,  0.02268523,\n",
              "          0.06489191,  0.04522332,  0.04159499,  0.05883703, -0.0679592 ,\n",
              "         -0.06814078,  0.01444547, -0.08391859,  0.02802531, -0.06822761,\n",
              "         -0.00544853, -0.0108375 ,  0.02592628,  0.05109527,  0.0481657 ,\n",
              "         -0.04014007, -0.04469495, -0.06159045,  0.0850151 ,  0.03590351,\n",
              "         -0.03850049, -0.00144946,  0.05089433, -0.0187868 , -0.00835431,\n",
              "         -0.04618165, -0.02929308,  0.02773698,  0.05458493, -0.01804651,\n",
              "          0.00873317, -0.05254867,  0.07925475,  0.0438237 , -0.03661335,\n",
              "         -0.02251817, -0.03254544,  0.08322661,  0.03754146, -0.05964416,\n",
              "         -0.0059575 ,  0.08285912, -0.0829063 , -0.04307079,  0.04826928,\n",
              "         -0.07567211, -0.06194926, -0.03587329, -0.03849047, -0.02060005,\n",
              "          0.06998672, -0.02570033, -0.01016574,  0.02126212, -0.00857124,\n",
              "         -0.06467243, -0.02527684,  0.05617353,  0.02333347, -0.02899949,\n",
              "         -0.07193917, -0.03088062, -0.0683749 , -0.00926945,  0.07574644,\n",
              "         -0.00010405,  0.0126499 , -0.07055654, -0.05963082, -0.07148142,\n",
              "          0.06528778,  0.01037598, -0.04063134, -0.05896816,  0.07497732,\n",
              "         -0.02305587, -0.0121356 ,  0.0851643 , -0.01492365,  0.06758108,\n",
              "          0.00086505, -0.04037582, -0.04342893, -0.08816309,  0.0808659 ,\n",
              "          0.00355343,  0.04761068, -0.06786671, -0.07798018,  0.07918046,\n",
              "          0.04853942, -0.05185395,  0.01014347,  0.01540445,  0.07371876,\n",
              "          0.00516264,  0.00171357, -0.00048698,  0.039972  ,  0.04335169,\n",
              "         -0.03195043,  0.01675101, -0.02032256, -0.05522547,  0.07893638,\n",
              "          0.06393861,  0.00336153,  0.01280002,  0.07873664, -0.06525356,\n",
              "         -0.03016198, -0.06538293,  0.00333562,  0.07008392, -0.06331918,\n",
              "          0.03115054, -0.05108894,  0.01201659, -0.03169418,  0.01224909,\n",
              "          0.0760593 , -0.05013447, -0.02498146,  0.04137865, -0.05009054,\n",
              "          0.03008747,  0.07642675, -0.04641014,  0.03577621, -0.00896409,\n",
              "         -0.00110111,  0.08674582, -0.01485097,  0.02020951,  0.08441552,\n",
              "         -0.06617235, -0.00620331,  0.07625804, -0.01184091,  0.01455662,\n",
              "          0.01410194,  0.04028825,  0.0653399 , -0.0042134 , -0.05994495,\n",
              "         -0.02686203,  0.02240432,  0.04596273, -0.02192957,  0.04368068,\n",
              "         -0.0378465 , -0.03682218, -0.07990394, -0.00222317, -0.03885592,\n",
              "         -0.00517528, -0.07690249, -0.05367391, -0.042418  , -0.05370116,\n",
              "         -0.06565571, -0.07203883, -0.05000737,  0.01913256, -0.06508868,\n",
              "         -0.04589529,  0.08505989, -0.06421202, -0.02267514,  0.08543979,\n",
              "          0.00824313, -0.02714631,  0.06648549, -0.05207874,  0.0319458 ,\n",
              "         -0.08806024, -0.04020843,  0.03901512,  0.08765825, -0.01971918,\n",
              "         -0.04754002, -0.08058286,  0.06228489, -0.0572468 ,  0.02353095,\n",
              "         -0.01640166,  0.08121874, -0.01541556, -0.02712769, -0.06431543,\n",
              "          0.08489222, -0.01473814, -0.07863954, -0.08197702, -0.07607937,\n",
              "          0.04491436,  0.00175474,  0.03733138, -0.07250303,  0.05370974,\n",
              "         -0.05684315,  0.00445385,  0.0186412 , -0.05851683,  0.05502003,\n",
              "          0.06951355, -0.00428431, -0.0692706 ,  0.05828959, -0.01446792,\n",
              "         -0.02006656,  0.06133295, -0.08132583,  0.05552114, -0.05937206,\n",
              "         -0.01749066,  0.04653551,  0.05601437,  0.07194703,  0.05715024,\n",
              "         -0.05098046, -0.00334186,  0.03874635,  0.04461428, -0.04255145,\n",
              "         -0.05435073,  0.0418062 , -0.08167708,  0.0406831 ,  0.0617611 ,\n",
              "          0.06226438,  0.05196419,  0.07335085, -0.00158936,  0.02028148,\n",
              "         -0.06580258, -0.05782177, -0.01013893, -0.01579893,  0.0707612 ,\n",
              "          0.03239734, -0.02282688, -0.05233123, -0.03948627,  0.02238224,\n",
              "         -0.03897358,  0.02018824,  0.03228164,  0.04220503,  0.02828851,\n",
              "         -0.02096992, -0.00683244, -0.03443049, -0.02384564,  0.0195175 ,\n",
              "         -0.08557368,  0.08535493,  0.06265663, -0.06125189, -0.07665314,\n",
              "          0.01366603, -0.01629266,  0.05237996, -0.08741819, -0.01351792,\n",
              "         -0.01685121,  0.05505075,  0.01130827, -0.00974441,  0.08341383,\n",
              "          0.014857  , -0.02094505, -0.05131535,  0.02452482, -0.0727656 ,\n",
              "         -0.06277889,  0.07365461,  0.05409767, -0.06291945,  0.06236693,\n",
              "         -0.03494645,  0.03749295,  0.05784669,  0.02026398,  0.03227837,\n",
              "         -0.02096278,  0.04265191,  0.05891045,  0.01213065,  0.06910496,\n",
              "         -0.03178594, -0.07661607,  0.01869753,  0.00423759, -0.06197748,\n",
              "         -0.04715399, -0.02519067, -0.04144327, -0.06009157, -0.02763982,\n",
              "          0.05414159,  0.08187001,  0.06716744, -0.04456571, -0.06579094,\n",
              "         -0.02989347,  0.01992279, -0.07653007,  0.01043957, -0.03683772,\n",
              "         -0.02593325, -0.00154783,  0.04482577,  0.07127661, -0.03522827,\n",
              "          0.0063797 , -0.00237653,  0.05872063, -0.03741111,  0.01744679,\n",
              "          0.08776098, -0.01667424, -0.00535961]], dtype=float32)>,\n",
              " <tf.Variable 'gru_1/recurrent_kernel:0' shape=(256, 768) dtype=float32, numpy=\n",
              " array([[ 0.06991972, -0.03397088,  0.03386964, ..., -0.02469888,\n",
              "         -0.01050543, -0.0054177 ],\n",
              "        [-0.00892148,  0.03367973, -0.02464885, ...,  0.0165314 ,\n",
              "         -0.00776899, -0.0103619 ],\n",
              "        [-0.02400255, -0.01269734,  0.07387166, ...,  0.01799576,\n",
              "          0.05279814, -0.00206613],\n",
              "        ...,\n",
              "        [ 0.03852737, -0.00519712, -0.05346568, ..., -0.0460299 ,\n",
              "         -0.01976767,  0.00563833],\n",
              "        [ 0.01455927,  0.02766004, -0.00516034, ..., -0.03650172,\n",
              "          0.03188919, -0.03452572],\n",
              "        [-0.03706405,  0.07915234, -0.0297339 , ...,  0.00853777,\n",
              "          0.0654306 ,  0.03057472]], dtype=float32)>,\n",
              " <tf.Variable 'gru_1/bias:0' shape=(768,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_7/kernel:0' shape=(256, 128) dtype=float32, numpy=\n",
              " array([[ 0.06125277, -0.10016635,  0.0627754 , ..., -0.05805916,\n",
              "          0.09220889,  0.0203822 ],\n",
              "        [-0.03259471,  0.11064062, -0.00781935, ..., -0.05914357,\n",
              "          0.03506657, -0.11737701],\n",
              "        [ 0.10967949,  0.02049941, -0.10221213, ..., -0.09792066,\n",
              "          0.06985378,  0.05810389],\n",
              "        ...,\n",
              "        [ 0.01180094, -0.01886371, -0.07480505, ...,  0.06071103,\n",
              "         -0.07087964, -0.10527819],\n",
              "        [ 0.06990692,  0.08021626, -0.03917879, ...,  0.03359976,\n",
              "          0.07039097,  0.0621604 ],\n",
              "        [ 0.026539  , -0.09450263, -0.03970584, ...,  0.09320194,\n",
              "         -0.00645187,  0.07280949]], dtype=float32)>,\n",
              " <tf.Variable 'dense_7/bias:0' shape=(128,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_8/kernel:0' shape=(128, 11) dtype=float32, numpy=\n",
              " array([[ 0.03951675,  0.03064278, -0.15516195, ...,  0.0060129 ,\n",
              "         -0.04926291,  0.02097863],\n",
              "        [-0.15011558, -0.11409825,  0.1398008 , ...,  0.08616818,\n",
              "          0.06615989,  0.04870529],\n",
              "        [ 0.20116271, -0.07153746,  0.00594023, ..., -0.07104956,\n",
              "          0.05189706,  0.11015768],\n",
              "        ...,\n",
              "        [-0.18524157,  0.01323251, -0.09962371, ...,  0.08110134,\n",
              "         -0.14866501,  0.20206924],\n",
              "        [-0.18793565, -0.09253323, -0.11896358, ...,  0.04170637,\n",
              "         -0.01279874, -0.11493538],\n",
              "        [ 0.00916821, -0.15030573, -0.17753017, ..., -0.00260323,\n",
              "          0.05450957,  0.01093341]], dtype=float32)>,\n",
              " <tf.Variable 'dense_8/bias:0' shape=(11,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rML15_Ay8qn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "809a5852-ef0f-477a-8f25-e0a0f909fda0"
      },
      "source": [
        "history = model.fit(gru_x_train, gru_y_train, epochs=20, batch_size=10, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 84 samples, validate on 22 samples\n",
            "Epoch 1/20\n",
            "84/84 [==============================] - 1s 7ms/step - loss: 2.3727 - accuracy: 0.0952 - val_loss: 2.3286 - val_accuracy: 0.2727\n",
            "Epoch 2/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.2930 - accuracy: 0.2143 - val_loss: 2.2292 - val_accuracy: 0.2273\n",
            "Epoch 3/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1828 - accuracy: 0.1310 - val_loss: 2.1776 - val_accuracy: 0.1818\n",
            "Epoch 4/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1424 - accuracy: 0.1429 - val_loss: 2.2007 - val_accuracy: 0.1364\n",
            "Epoch 5/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1272 - accuracy: 0.1786 - val_loss: 2.1839 - val_accuracy: 0.2273\n",
            "Epoch 6/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1321 - accuracy: 0.2024 - val_loss: 2.2145 - val_accuracy: 0.0909\n",
            "Epoch 7/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1224 - accuracy: 0.1786 - val_loss: 2.1805 - val_accuracy: 0.0909\n",
            "Epoch 8/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1194 - accuracy: 0.1786 - val_loss: 2.1882 - val_accuracy: 0.0909\n",
            "Epoch 9/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1127 - accuracy: 0.1786 - val_loss: 2.1961 - val_accuracy: 0.0909\n",
            "Epoch 10/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1088 - accuracy: 0.1786 - val_loss: 2.2107 - val_accuracy: 0.0909\n",
            "Epoch 11/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1033 - accuracy: 0.1786 - val_loss: 2.2234 - val_accuracy: 0.0909\n",
            "Epoch 12/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.0951 - accuracy: 0.2143 - val_loss: 2.2070 - val_accuracy: 0.1818\n",
            "Epoch 13/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.1015 - accuracy: 0.2024 - val_loss: 2.2069 - val_accuracy: 0.2727\n",
            "Epoch 14/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.0878 - accuracy: 0.2381 - val_loss: 2.2162 - val_accuracy: 0.2727\n",
            "Epoch 15/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.0784 - accuracy: 0.2143 - val_loss: 2.2271 - val_accuracy: 0.1818\n",
            "Epoch 16/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.0729 - accuracy: 0.2738 - val_loss: 2.2237 - val_accuracy: 0.1364\n",
            "Epoch 17/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.0695 - accuracy: 0.2024 - val_loss: 2.2205 - val_accuracy: 0.2727\n",
            "Epoch 18/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.0563 - accuracy: 0.2381 - val_loss: 2.1917 - val_accuracy: 0.3182\n",
            "Epoch 19/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.0417 - accuracy: 0.3095 - val_loss: 2.1930 - val_accuracy: 0.2273\n",
            "Epoch 20/20\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 2.0542 - accuracy: 0.2381 - val_loss: 2.1956 - val_accuracy: 0.2727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pEAjO3czQ3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "077d42c0-12c0-493a-8e89-d98dc0da80a3"
      },
      "source": [
        "scores = model.evaluate(gru_x_train, gru_y_train)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
        "model.reset_states()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106/106 [==============================] - 0s 175us/step\n",
            "accuracy: 28.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG3dzRWq06bi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "9ece4160-e919-4b2b-9342-e9799e4e5002"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', color='red',label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# loss 그래프를 살펴보면 Training loss는 점점 하락.\n",
        "# 하지만 Vaildation loss는 높아지는 것을 봤을 때 과적합인것을 의심 가능."
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccjOoyhozBrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_count = 106 # 최대 예측 개수 정의"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-x4uDGCzF81",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "772167fe-f724-49c6-d3e6-ce61b7b277ef"
      },
      "source": [
        "# 한 스텝 예측\n",
        "\n",
        "one_step_seq_out = ['g4','e8','f8','g4']\n",
        "pred_out = model.predict(gru_x_train)\n",
        "\n",
        "for i in range(pred_count):\n",
        "    idx = np.argmax(pred_out[i]) # 인덱스의 최대값을 뽑아옴. \n",
        "    one_step_seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n",
        "    \n",
        "print(\"one step prediction : \", one_step_seq_out)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one step prediction :  ['g4', 'e8', 'f8', 'g4', 'f8', 'f8', 'f8', 'f8', 'f8', 'c8', 'c8', 'e8', 'e8', 'e8', 'f8', 'f8', 'e8', 'e8', 'e8', 'e8', 'f8', 'f8', 'f8', 'e8', 'f8', 'f8', 'f8', 'e8', 'c8', 'c8', 'c8', 'c8', 'c8', 'e8', 'e8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'c8', 'c8', 'c8', 'c8', 'c8', 'e8', 'e8', 'e8', 'e8', 'c8', 'c8', 'e8', 'e8', 'e8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'c8', 'c8', 'e8', 'e8', 'e8', 'e8', 'f8', 'e8', 'e8', 'e8', 'f8', 'f8', 'f8', 'f8', 'e8', 'f8', 'f8', 'f8', 'e8', 'c8', 'c8', 'c8', 'c8', 'c8', 'e8', 'e8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'c8', 'c8', 'c8', 'c8', 'c8', 'e8', 'c8', 'e8', 'e8', 'e8', 'e8', 'e8', 'c8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1htLIqU_zIK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "564a7942-33fb-4f56-8ab6-5b5e6c3bc887"
      },
      "source": [
        "# 곡 전체 예측\n",
        "\n",
        "seq_in = ['g4','e8','f8','g4']\n",
        "full_seq_out = seq_in\n",
        "seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n",
        "\n",
        "for i in range(pred_count):\n",
        "    sample_in = np.array(seq_in)  # [0.9 0.7 0.8 0.9]\n",
        "    sample_in = np.reshape(sample_in, (1, 4, 1)) # [[0.9 0.7 0.8 0.9]], batch_size, feature, attribute\n",
        "    pred_out = model.predict(sample_in) # [[0.9 0.7 0.8 0.9]] 이것만 갖고 예측하도록 만든 곳......\n",
        "    idx = np.argmax(pred_out)  # 10\n",
        "    full_seq_out.append(idx2code[idx]) \n",
        "    seq_in.append(idx / float(max_idx_value))  # 10/10.0\n",
        "    seq_in.pop(0)\n",
        "   \n",
        "print(\"full song prediction : \", full_seq_out)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "full song prediction :  ['g4', 'e8', 'f8', 'g4', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwsX9-Or1YZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    }
  ]
}